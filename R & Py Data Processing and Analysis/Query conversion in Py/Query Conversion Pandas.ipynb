{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9af6762b",
   "metadata": {},
   "source": [
    "# `DPRPy Assignment 2`\n",
    "### By: Naveen Tiwari\n",
    "\n",
    "## `Overview`\n",
    "- This document is related to the `second assignment` from the subject `Data Processing in R and Python`. It Contains the codes for each queries, which includes compare the codes with the asked `SQLite query`, using the `.equals() method`. \n",
    "\n",
    "- This report includes solution of the SQlite query using Python codes based on `pandas and numpy library`. \n",
    "- I have imported my Python codes into the notebook, in order to do the comparision.\n",
    "- The imported data from the `CSV files` has been loaded to the temporary `SQLite database` which will be used to run the reference `SQL solutions`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Imprting the required libraries, Python solutions and CSV files:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Naveen_Tiwari_assignment_2 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Posts = pd.read_csv(\"/Users/naveen/Downloads/Posts.csv\", compression = None)\n",
    "Users = pd.read_csv(\"/Users/naveen/Downloads/Users.csv\", compression = None)\n",
    "Badges = pd.read_csv(\"/Users/naveen/Downloads/Badges.csv\", compression = None)\n",
    "Comments = pd.read_csv(\"/Users/naveen/Downloads/Comments.csv\", compression = None)\n",
    "Votes = pd.read_csv(\"/Users/naveen/Downloads/Votes.csv\", compression = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Creating SQLite database`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002408"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, os.path\n",
    "import sqlite3\n",
    "import tempfile\n",
    "\n",
    "# path to database file\n",
    "db = os.path.join(tempfile.mkdtemp(), 'assig2.db')\n",
    "\n",
    "if os.path.isfile(db): # if this file already exists...\n",
    "    os.remove(db) # ...we will remove it\n",
    "\n",
    "conn = sqlite3.connect(db) # create the connection\n",
    "\n",
    "Badges.to_sql(\"Badges\", conn) # import the data frame into the database Comments.to_sql(\"Comments\", conn)\n",
    "Comments.to_sql(\"Comments\", conn)\n",
    "Posts.to_sql(\"Posts\", conn)\n",
    "Users.to_sql(\"Users\", conn)\n",
    "Votes.to_sql(\"Votes\", conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42f656f7",
   "metadata": {},
   "source": [
    "## `First Query`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL\n",
    "result_sql = pd.read_sql_query(\"\"\"\n",
    "SELECT STRFTIME('%Y', CreationDate) AS Year, COUNT(*) AS TotalNumber FROM Posts\n",
    "GROUP BY Year\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas\n",
    "res = solution_1(Posts)\n",
    "\n",
    "# Compare\n",
    "result_sql.equals(res)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query explanation:**\n",
    "\n",
    "- The `SQL query` asked to select just the `Year part` of the \"CreationDate column\" from the `Posts` csv file, and count the number of occurrence of each Year.\n",
    "\n",
    "- So I just selected the Year part to get the appropriate date format, and renamed the  number of occurrence column as `TotalNumber`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Second Query`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SQL\n",
    "result_sql = pd.read_sql_query(\"\"\"\n",
    "SELECT Id, DisplayName, SUM(ViewCount) AS TotalViews FROM Users\n",
    "JOIN (\n",
    "SELECT OwnerUserId, ViewCount FROM Posts WHERE PostTypeId = 1 ) AS Questions\n",
    "ON Users.Id = Questions.OwnerUserId GROUP BY Id\n",
    "ORDER BY TotalViews DESC\n",
    "LIMIT 10\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas\n",
    "res = solution_2(Users, Posts)\n",
    "\n",
    "# Compare\n",
    "result_sql.equals(res.reset_index(drop=True))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query explanation:**\n",
    "\n",
    "- In the SQL query it was asked to select some columns from the `Posts and Users` csv file and then, rename it and perform some operations.After that we have to `inner join` them. Then we have to order it by \"TotalViews\" column by `decreasing, with a limit of 10`.\n",
    "\n",
    "- I selected the data only when `PosTtypeId = 1` from the \"Posts csv file\", and other columns as \"Questions\". Then I got the `sum of column ViewCount as TotalViews`.\n",
    "After that performed it's `inner join` with of \"Users csv file Id's part\". Then we ordered the data of  `TotalViews` as decreasing with the `limit of 10`.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Third Query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SQL\n",
    "result_sql= pd.read_sql_query(\"\"\"\n",
    "SELECT Year, Name, MAX((Count * 1.0) / CountTotal) AS MaxPercentage\n",
    "FROM (\n",
    "SELECT BadgesNames.Year, BadgesNames.Name, BadgesNames.Count, BadgesYearly.CountTotal\n",
    "FROM (\n",
    "SELECT Name, COUNT(*) AS Count, STRFTIME('%Y', Badges.Date) AS Year FROM Badges\n",
    "GROUP BY Name, Year\n",
    ") AS BadgesNames \n",
    "JOIN (\n",
    "SELECT COUNT(*) AS CountTotal, STRFTIME('%Y', Badges.Date) AS Year FROM Badges\n",
    "GROUP BY YEAR\n",
    ") AS BadgesYearly\n",
    "ON BadgesNames.Year = BadgesYearly.Year\n",
    ")\n",
    "GROUP BY Year\n",
    "\"\"\", conn)\n",
    "\n",
    "#pandas\n",
    "res = solution_3(Badges) \n",
    "\n",
    "#compare\n",
    "result_sql.equals(res)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query explanation:**\n",
    "\n",
    "- The SQL query asked to compute the `maximum percentage` of badges per `year by names`. so that we can check number of badges assoiciated with a name, in comparision to the total number of badges per year.\n",
    "\n",
    "- For `BadgesNames`, I selected the year part to get the required date format from `column Date of Badges csv file`.After that I did the counted the frequency of each year and did the renaming of the Date column as `Year` and the count part as `Count`. The same I did for `BadgesYearly` part, but here we just had to select count as `CountTotal` and `Year`.\n",
    "- Then I did the `inner join` of `BadgesNames` and `BadgesYearly` by `Year`. After that I divided the Count and CountTotal column, and calculated the Max part, and after that did the renaming to get the desired results.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Fourth Query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SQL\n",
    "result_sql= pd.read_sql_query(\"\"\"\n",
    "SELECT Title, CommentCount, ViewCount, CommentsTotalScore, DisplayName, Reputation, Location FROM (\n",
    "SELECT Posts.OwnerUserId, Posts.Title, Posts.CommentCount, Posts.ViewCount, CmtTotScr.CommentsTotalScore\n",
    "FROM (\n",
    "SELECT PostId, SUM(Score) AS CommentsTotalScore FROM Comments\n",
    "GROUP BY PostId\n",
    ") AS CmtTotScr\n",
    "JOIN Posts ON Posts.Id = CmtTotScr.PostId WHERE Posts.PostTypeId=1\n",
    ") AS PostsBestComments\n",
    "JOIN Users ON PostsBestComments.OwnerUserId = Users.Id ORDER BY CommentsTotalScore DESC\n",
    "LIMIT 10\n",
    "\"\"\", conn)\n",
    "\n",
    "#pandas\n",
    "res = solution_4(Users, Posts, Comments)    \n",
    "\n",
    "#compare\n",
    "result_sql.equals(res.reset_index(drop=True))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query explanation:**\n",
    "\n",
    "- The SQL query asked to display `posts having comments with most total score`. Alomg with User's displayed name, reputation and location). Also the post title, number of comments and the total view count of the post. \n",
    "\n",
    "- I got the `sum` of the \"Score column\" from the `Comments` csv file. After that I renamed it as `CommentsTotalScore`, and then I joined it with `PostId` from the `Comments` csv file, with the filter of `PostTypeId = 1`.\n",
    "After that I selected the required columns and again did the `inner join`.\n",
    "Then filtered the data of`CommentTotalScore` in `decreasing order` with the limit of `10`.  \n",
    "At last I selected the required columns for the output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Fifth Query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SQL\n",
    "result_sql = pd.read_sql_query(\"\"\"\n",
    "SELECT Posts.Title, STRFTIME('%Y-%m-%d', Posts.CreationDate) AS Date, VotesByAge.* FROM Posts\n",
    "JOIN (\n",
    "SELECT PostId,\n",
    "MAX(CASE WHEN VoteDate = 'before' THEN Total ELSE 0 END) BeforeCOVIDVotes, MAX(CASE WHEN VoteDate = 'during' THEN Total ELSE 0 END) DuringCOVIDVotes, MAX(CASE WHEN VoteDate = 'after' THEN Total ELSE 0 END) AfterCOVIDVotes, SUM(Total) AS Votes\n",
    "FROM (\n",
    "SELECT PostId,\n",
    "CASE STRFTIME('%Y', CreationDate) WHEN '2022' THEN 'after'\n",
    "WHEN '2021' THEN 'during' WHEN '2020' THEN 'during' WHEN '2019' THEN 'during' ELSE 'before'\n",
    "END VoteDate, COUNT(*) AS Total FROM Votes\n",
    "WHERE VoteTypeId IN (3, 4, 12) GROUP BY PostId, VoteDate\n",
    ") AS VotesDates\n",
    "GROUP BY VotesDates.PostId\n",
    ") AS VotesByAge ON Posts.Id = VotesByAge.PostId WHERE Title NOT IN ('') AND DuringCOVIDVotes > 0 ORDER BY DuringCOVIDVotes DESC, Votes DESC\n",
    "LIMIT 20\n",
    "\"\"\", conn)\n",
    "\n",
    "#pandas\n",
    "res = solution_5(Votes,Posts)   \n",
    "\n",
    "#compare\n",
    "result_sql.equals(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query explanation:**\n",
    "\n",
    "- The SQL query asked to display posts having `maximum downvotes, spam or offensive votes`. By selecting the apporopriate columns, for the pandemic situvation which was divided into three time periods `before, during, after`.\n",
    "\n",
    "- Firstly I got the required filter for column `VoteTypeId`, afterwards got the desired date format for column `CreationDate`. Then I did the grouping and `dictionary` for  both `WHEN THEN` parts. \n",
    "\n",
    "- Then I calculated the sum of column `Total` as `Votes`, afterwards got the desired date format for column `CreationDate` for `Posts` csv file.\n",
    "Did the filtering for `Title and BeforeCOVIDVotes` as asked.\n",
    "Finished the `ordering and limiting part`selected the required column for output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after finishing work, we close the connection #\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
